## Demo: https://youtu.be/zh5fOongFKk

## 🏁 Goal
The goal is to provide a backend detection system that can be used in content moderation pipelines, particularly for live streaming platforms using HLS streaming on realtime

A backend system designed for detecting NSFW (Not Safe For Work) content in videos streamed via HLS (HTTP Live Streaming). Built for competition purposes as part of HueICTC.

This project is developed by a team of students participating in the HueICTC competition.

## 👥 TEAM:
 
Le Phi Phat - HUSC

Tran Duc Minh - HUST

Tran Tien Dat - HCMUT

## 🚀 Tech Stack

Video Processing: FFmpeg

NSFW Detection Model: 

Storage: Local / S3 / MinIO

Queue System (Optional): RabbitMQ 

Containerization: Docker

## 🔧 Install

## 📄 License
