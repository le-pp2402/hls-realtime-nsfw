## Demo: https://youtu.be/zh5fOongFKk

## ğŸ Goal
The goal is to provide a backend detection system that can be used in content moderation pipelines, particularly for live streaming platforms using HLS streaming on realtime

A backend system designed for detecting NSFW (Not Safe For Work) content in videos streamed via HLS (HTTP Live Streaming).

## ğŸ‘¥ TEAM:
 
Le Phi Phat - HUSC

Tran Duc Minh - HUST

Tran Tien Dat - HCMUT

## ğŸš€ Tech Stack

Video Processing: FFmpeg

NSFW Detection Model: 

Storage: Local / S3 / MinIO

Queue System (Optional): RabbitMQ 

Containerization: Docker

## ğŸ”§ Install

## ğŸ“„ License


## TODO
[ ] Add redis to cache duplicate input of model nsfw detector
![Screenshot from 2025-06-12 14-54-52](https://github.com/user-attachments/assets/622ce96b-c974-46fb-84df-14144f2172c3)
